{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab5BM2.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOjQNoJekoxAFZl9AaXiaOH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bareera2505/Deep-Learning-Labs/blob/main/Lab5BM2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fAdzD21n7QB1",
        "outputId": "d3be28eb-c712-4311-af5d-65847f12b272"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4oPaJtO1_Mi",
        "outputId": "48a30380-ace0-446a-b448-461a41b4e65b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torch import nn\n",
        "from torchvision import datasets, models, transforms\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "import zipfile\n",
        "import glob\n",
        "from PIL import Image\n",
        "import cv2 as cv\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.cuda.device_count())\n",
        "print(torch.cuda.get_device_name(0))\n",
        "cuda0 = torch.device('cuda:0')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hRss1SlU2QCL",
        "outputId": "1f988c57-bda3-4145-9fda-cabe0441f1cd"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 100\n",
        "learning_rate=0.0001"
      ],
      "metadata": {
        "id": "rXcIwBBQ2alZ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "base_dir = '/content/drive/MyDrive/Colab Notebooks/'\n",
        "train_dir = '/content/drive/MyDrive/Colab Notebooks/train/'\n",
        "test_dir = '/content/drive/MyDrive/Colab Notebooks/test/'\n",
        "train_list = glob.glob(os.path.join(train_dir,'*.jpg'))\n",
        "test_list = glob.glob(os.path.join(test_dir, '*.jpg'))\n",
        "print(f'Length of training data: {len(train_list)}')\n",
        "print(f'Length of test data: {len(test_list)}')\n",
        "train_list, val_list = train_test_split(train_list, test_size=0.2)\n",
        "#data Augumentation\n",
        "train_transforms =  transforms.Compose([\n",
        "        transforms.Resize((227, 227)),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) \n",
        "    ])\n",
        "\n",
        "val_transforms = transforms.Compose([\n",
        "        transforms.Resize((227, 227)),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "\n",
        "test_transforms = transforms.Compose([   \n",
        "    transforms.Resize((227, 227)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "test_transforms_not_normalized = transforms.Compose([   \n",
        "    transforms.Resize((227, 227)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    #transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "class dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self,file_list,transform=None):\n",
        "        self.file_list = file_list\n",
        "        self.transform = transform\n",
        "        \n",
        "    #dataset length\n",
        "    def __len__(self):\n",
        "        self.filelength = len(self.file_list)\n",
        "        return self.filelength\n",
        "    \n",
        "    #load an one of images\n",
        "    def __getitem__(self,idx):\n",
        "        img_path = self.file_list[idx]\n",
        "        img = Image.open(img_path)\n",
        "        img_transformed = self.transform(img)\n",
        "        \n",
        "        label = img_path.split('/')[-1].split('.')[0]\n",
        "        if label == 'dog':\n",
        "            label=1\n",
        "        elif label == 'cat':\n",
        "            label=0\n",
        "            \n",
        "        return img_transformed,label\n",
        "\n",
        "train_data = dataset(train_list, transform=train_transforms)\n",
        "test_data = dataset(test_list, transform=test_transforms)\n",
        "test_data_not_normalized = dataset(test_list, transform=test_transforms_not_normalized)\n",
        "val_data = dataset(val_list, transform=test_transforms)\n",
        "train_loader = torch.utils.data.DataLoader(dataset = train_data, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(dataset = test_data, batch_size=batch_size, shuffle=False)\n",
        "test_loader_not_normalized = torch.utils.data.DataLoader(dataset = test_data_not_normalized, batch_size=batch_size, shuffle=False)\n",
        "val_loader = torch.utils.data.DataLoader(dataset = val_data, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "#Took help from these resources for data loading\n",
        "#https://www.kaggle.com/code/lys620/basic-pytorch-cnn-tutorial/notebook\n"
      ],
      "metadata": {
        "id": "092L7BxZ2eyz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AlexNet(nn.Module):\n",
        "\n",
        "    def __init__(self, num_classes=2):\n",
        "        super(AlexNet, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            \n",
        "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            \n",
        "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            \n",
        "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            \n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "        )\n",
        "        \n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
        "        \n",
        "        self.classifier = nn.Sequential(\n",
        "        \n",
        "            nn.Dropout(),\n",
        "            nn.Linear(256 * 6 * 6, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(4096, num_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.classifier(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "d1gLwU-f23hG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def imshow(img):\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.figure(figsize=(20,20))\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "\n",
        "\n",
        "# get some random training images\n",
        "dataiter = iter(train_loader)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "\n",
        "# show images\n",
        "imshow(torchvision.utils.make_grid(images))"
      ],
      "metadata": {
        "id": "qeS47pOt70oQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#conv_list = [0,3,6,8,10]\n",
        "#fc_list = [1,4,6]\n",
        "#for i in conv_list:\n",
        "    #torch.nn.init.kaiming_normal_(Alexnet.features[i].weight)\n",
        "#for i in fc_list:\n",
        "    #torch.nn.init.kaiming_normal_(Alexnet.classifier[i].weight)\n"
      ],
      "metadata": {
        "id": "RB1iGRaO8GTk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "import time"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qWKkSSeC8vtW",
        "outputId": "4a95957c-a5c5-43db-a871-8917342ffaab"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 3 µs, sys: 1 µs, total: 4 µs\n",
            "Wall time: 8.58 µs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Definition of hyperparameters\n",
        "model = AlexNet().to(cuda0)\n",
        "\n",
        "# Cross Entropy Loss \n",
        "error = nn.CrossEntropyLoss() \n",
        "\n",
        "# Adam Optimizer\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "num_epochs=6"
      ],
      "metadata": {
        "id": "acREae1A8JWb"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize arrays to hold loss and accuracy data\n",
        "train_loss_list = np.zeros((num_epochs,))\n",
        "accuracy_list = np.zeros((num_epochs,))\n",
        "\n",
        "for epoch in tqdm.trange(num_epochs):\n",
        "  total_train_loss = 0\n",
        "  total_val_loss = 0\n",
        "\n",
        "  for imgs,labels in train_loader:\n",
        "    # calculate training loss on model\n",
        "    imgs = imgs.to(cuda0)\n",
        "    labels = labels.to(cuda0)\n",
        "    y_pred = model(imgs).to(cuda0)\n",
        "    loss = error(y_pred, labels)\n",
        "    total_train_loss += loss\n",
        "    \n",
        "    # zero gradients, backwards pass, and step\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "  train_loss_list[epoch] = total_train_loss/len(train_loader)\n",
        "\n",
        "\n",
        "  # Calculate accuracy\n",
        "  imgs_test, labels_test = next(iter(val_loader))\n",
        "  imgs_test = imgs_test.to(cuda0)\n",
        "  labels_test = labels_test.to(cuda0)\n",
        "  #labels_test = labels_test.type(torch.FloatTensor).to(cuda0)\n",
        "  with torch.no_grad():\n",
        "    y_pred = model(imgs_test)\n",
        "    correct = (torch.argmax(y_pred, dim=1) == labels_test).type(torch.FloatTensor)\n",
        "    accuracy_list[epoch] = correct.mean()\n",
        "  print(f'Epoch: {epoch+1}, Training Loss: {train_loss_list[epoch]:0.5f}, Accuracy: {accuracy_list[epoch]:0.5f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qxwR1DJt83P1",
        "outputId": "dc224d4a-4cbb-4fad-afb0-af4fa9421ee5"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 17%|█▋        | 1/6 [05:01<25:05, 301.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, Training Loss: 0.64019, Accuracy: 0.70000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 33%|███▎      | 2/6 [06:58<12:51, 192.91s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 2, Training Loss: 0.49696, Accuracy: 0.71000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 3/6 [08:54<07:53, 157.99s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 3, Training Loss: 0.41143, Accuracy: 0.87000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|██████▋   | 4/6 [10:51<04:43, 141.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 4, Training Loss: 0.34251, Accuracy: 0.79000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 83%|████████▎ | 5/6 [12:48<02:12, 132.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 5, Training Loss: 0.30263, Accuracy: 0.88000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [14:45<00:00, 147.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 6, Training Loss: 0.25642, Accuracy: 0.90000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save model\n",
        "torch.save(model, '/content/drive/MyDrive/Colab Notebooks/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "id": "KR1hS5eh46jA",
        "outputId": "591ea21d-76e2-4ccb-838f-cadb3c3103d9"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-7fba221e835a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# save model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'/content/drive/MyDrive/Colab Notebooks/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# plot test accuracy and training loss\n",
        "fig, (ax1, ax2) = plt.subplots(2, figsize=(12, 6), sharex=True)\n",
        "\n",
        "ax1.plot(accuracy_list,label='Accuracy')\n",
        "ax1.set_ylabel(\"Accuracy\")\n",
        "ax1.legend()\n",
        "ax2.plot(train_loss_list,label='training loss')\n",
        "#ax2.plot(val_loss_list,label='validation loss')\n",
        "ax2.legend()\n",
        "ax2.set_ylabel(\"Training Loss\")\n",
        "ax2.set_xlabel(\"epochs\");\n",
        "fig.suptitle(f'Optimizer: Adam \\n lr = 0.001 epochs = {num_epochs} \\n Max Accuracy = {max(accuracy_list):.3f}')"
      ],
      "metadata": {
        "id": "Vt8JuHGN5PvJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get images and labels for test set\n",
        "imgs_test, labels_test = next(iter(test_loader))\n",
        "imgs_test = imgs_test.to(cuda0)\n",
        "with torch.no_grad():\n",
        "  y_pred = model(imgs_test)"
      ],
      "metadata": {
        "id": "dSckQSc_5dN7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get guesses\n",
        "guesses = torch.argmax(y_pred, dim=1) \n",
        "\n",
        "# get probabilities\n",
        "smax=nn.Softmax(dim=1)\n",
        "probability,_ = torch.max(smax(y_pred),dim=1) \n",
        "\n",
        "imgs_test_not_normalized, labels_test_not_normalized = next(iter(test_loader_not_normalized))"
      ],
      "metadata": {
        "id": "wITN-EeY5j6K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot classification accuracy\n",
        "f,ax=plt.subplots(3,8,figsize=(26,13))\n",
        "for i,(axs,predicted,true,prob) in enumerate(zip(ax.reshape(-1),guesses,labels_test,probability)):\n",
        "  axs.imshow(imgs_test_not_normalized[i].permute(1,2,0))\n",
        "  if predicted == 1:\n",
        "            predicted='Dog'\n",
        "  elif predicted == 0:\n",
        "            predicted='Cat'\n",
        "  axs.set_title(f'Prediction: {predicted} \\n Probability: {prob:0.5f}')\n",
        "  axs.axis('off')\n",
        "f.suptitle('AlexNet Cat/Dog Classification Test')"
      ],
      "metadata": {
        "id": "_9OIc4NS506X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **VISUALIZATION**"
      ],
      "metadata": {
        "id": "S0F-DLc06C20"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load the model\n",
        "print(model)\n",
        "model_weights = [] # we will save the conv layer weights in this list\n",
        "conv_layers = [] # we will save the 49 conv layers in this list\n",
        "# get all the model children as list\n",
        "model_children = list(model.children())\n",
        "model_children = model_children[0] "
      ],
      "metadata": {
        "id": "ibnV2zgq6BzF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# counter to keep count of the conv layers\n",
        "counter = 0 \n",
        "# append all the conv layers and their respective weights to the list\n",
        "for i in range(len(model_children)):\n",
        "    if type(model_children[i]) == nn.Conv2d:\n",
        "      counter += 1\n",
        "      model_weights.append(model_children[i].weight)\n",
        "      conv_layers.append(model_children[i])\n",
        "    elif type(model_children[i]) == nn.Sequential:\n",
        "      print('hi again')\n",
        "      for j in range(len(model_children[i])):\n",
        "          for child in model_children[i][j].children():\n",
        "              if type(child) == nn.Conv2d:\n",
        "                  counter += 1\n",
        "                  model_weights.append(child.weight)\n",
        "                  conv_layers.append(child)\n",
        "print(f\"Total convolutional layers: {counter}\")"
      ],
      "metadata": {
        "id": "2fZ21vJM6WJa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# read and visualize an image\n",
        "img = cv.imread(train_list[3])\n",
        "img = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
        "f,ax=plt.subplots(figsize=(15,5))\n",
        "ax.imshow(img)\n",
        "ax.axis('off')\n",
        "# define the transforms\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.Resize((512, 512)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "img = np.array(img)\n",
        "# apply the transforms\n",
        "img = transform(img).to(cuda0)\n",
        "\n",
        "# unsqueeze to add a batch dimension\n",
        "img = img.unsqueeze(0)\n",
        "\n",
        "# pass the image through all the layers\n",
        "results = [conv_layers[0](img)]\n",
        "for i in range(1, len(conv_layers)):\n",
        "    # pass the result from the last layer to the next layer\n",
        "    results.append(conv_layers[i](results[-1]))\n",
        "# make a copy of the `results`\n",
        "outputs = results\n",
        "\n",
        "# visualize 64 features from each layer \n",
        "# (although there are more feature maps in the upper layers)\n",
        "for num_layer in range(len(outputs)):\n",
        "    plt.figure(figsize=(15, 2))\n",
        "    plt.suptitle(f'Convolutional Layer {num_layer+1}')\n",
        "    layer_viz = outputs[num_layer][0, :, :, :]\n",
        "    layer_viz = layer_viz.data\n",
        "    for i, filter in enumerate(layer_viz):\n",
        "        if i == 9: # we will visualize only 9 feature maps in each layer\n",
        "            break\n",
        "        plt.subplot(1, 9, i + 1)\n",
        "        filter = filter.cpu()\n",
        "        plt.imshow(filter, cmap='gray')\n",
        "        plt.axis(\"off\")"
      ],
      "metadata": {
        "id": "lE-AKMo06dSr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}